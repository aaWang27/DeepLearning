{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0b7fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f57fc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Bank_Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2ac0d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a5ba52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df[df['Exited']==0]\n",
    "df_class1 = df[df['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7309a1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 11)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0c364d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 11)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0339fef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([df_class0['Age'], df_class1['Age']], color=['red', 'green'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fa58866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5d8ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_column_values(df):\n",
    "    for column in df:\n",
    "        print('{}: {}'.format(column, df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef51bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography: ['France' 'Spain' 'Germany']\n",
      "Gender: ['Female' 'Male']\n",
      "Age: [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure: [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance: [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts: [1 3 2 4]\n",
      "HasCrCard: [1 0]\n",
      "IsActiveMember: [1 0]\n",
      "EstimatedSalary: [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited: [1 0]\n"
     ]
    }
   ],
   "source": [
    "print_column_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e2fa46fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0199b0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          0  Female   42       2       0.00              1   \n",
       "1             608          2  Female   41       1   83807.86              1   \n",
       "2             502          0  Female   42       8  159660.80              3   \n",
       "3             699          0  Female   39       1       0.00              2   \n",
       "4             850          2  Female   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          0    Male   39       5       0.00              2   \n",
       "9996          516          0    Male   35      10   57369.61              1   \n",
       "9997          709          0  Female   36       7       0.00              1   \n",
       "9998          772          1    Male   42       3   75075.31              2   \n",
       "9999          792          0  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'] = df['Geography'].replace({'France': 0, 'Germany': 1, 'Spain': 2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf540e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          0       0   42       2       0.00              1   \n",
       "1             608          2       0   41       1   83807.86              1   \n",
       "2             502          0       0   42       8  159660.80              3   \n",
       "3             699          0       0   39       1       0.00              2   \n",
       "4             850          2       0   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          0       1   39       5       0.00              2   \n",
       "9996          516          0       1   35      10   57369.61              1   \n",
       "9997          709          0       0   36       7       0.00              1   \n",
       "9998          772          1       1   42       3   75075.31              2   \n",
       "9999          792          0       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].replace({'Female': 0, 'Male': 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4177220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography            int64\n",
       "Gender               int64\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "67b3cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f1764181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']] = scaler.fit_transform(df[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "114b574a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0        0.538          0       0  0.324324     0.2  0.000000              1   \n",
       "1        0.516          2       0  0.310811     0.1  0.334031              1   \n",
       "2        0.304          0       0  0.324324     0.8  0.636357              3   \n",
       "3        0.698          0       0  0.283784     0.1  0.000000              2   \n",
       "4        1.000          2       0  0.337838     0.2  0.500246              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1         0.506735       1  \n",
       "1          0               1         0.562709       0  \n",
       "2          1               0         0.569654       1  \n",
       "3          0               0         0.469120       0  \n",
       "4          1               1         0.395400       0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "272b46a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19c7ee4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f608f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "104145dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, X_test, y_train, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(10, input_dim=10, activation='relu'),\n",
    "        keras.layers.Dense(7, activation='relu'),\n",
    "        keras.layers.Dense(4, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                 loss=loss,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    if weights==-1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight=weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    print('Classification report: \\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "73a55051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7954\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.7954\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7962\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8031\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8129\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4157 - accuracy: 0.8155\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4094 - accuracy: 0.8184\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4060 - accuracy: 0.8223\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8215\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3988 - accuracy: 0.8264\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3952 - accuracy: 0.8270\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8282\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8298\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8313\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8381\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8351\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8391\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8401\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3722 - accuracy: 0.8439\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3691 - accuracy: 0.8446\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8454\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8472\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8499\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3631 - accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8511\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8509\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8551\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8530\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8550\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8536\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8560\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8572\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8572\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8565\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8566\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8584\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8566\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8577\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8562\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8572\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8574\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8572\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8572\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8591\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8579\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8585\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8574\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8583\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8554\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8579\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8574\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8566\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8591\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8576\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8594\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8564\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8589\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8585\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8597\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8584\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8585\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8595\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8581\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8577\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8599\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8610\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8609\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8599\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8596\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8602\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8608\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8590\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8605\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8611\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8577\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8622\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8611\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8595\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8618\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8615\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8619\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8618\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8609\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8601\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8620\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8630\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8612\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8615\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8606\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8612\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8540\n",
      "[0.3596506714820862, 0.8539999723434448]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91      1600\n",
      "           1       0.79      0.37      0.50       400\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.83      0.67      0.71      2000\n",
      "weighted avg       0.85      0.85      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, X_test, y_train, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222ce1a",
   "metadata": {},
   "source": [
    "### Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9d13c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "585240b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0, count_class1 = df['Exited'].value_counts()\n",
    "count_class0, count_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59fa2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df[df['Exited']==0]\n",
    "df_class1 = df[df['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e103a6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 11)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under_class0 = df_class0.sample(2037)\n",
    "df_under_class0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cab58052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4074, 11)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under_total = pd.concat([df_under_class0, df_class1], axis=0)\n",
    "df_under_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fa3f2f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2037\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under_total['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c03e0797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2037\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_under = df_under_total.drop('Exited', axis=1)\n",
    "y_under = df_under_total['Exited']\n",
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fd0f1c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3259, 10), (815, 10))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=37)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c5f4d9bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 2s 7ms/step - loss: 0.6833 - accuracy: 0.6017\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.6075\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6336\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6419\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.6585\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6628\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6751\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6843\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.6910\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.6984\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7027\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7014\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7119\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7085\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7125\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7174\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7195\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7248\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7254\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7297\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7315\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7352\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7315\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7392\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7395\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7423\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7444\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7475\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7490\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7478\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7515\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7490\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7545\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7524\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7527\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7512\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7582\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7512\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7527\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7545\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7542\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7570\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7610\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7582\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7656\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7625\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7579\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7570\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7637\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7643\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7668\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7659\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7653\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7659\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7674\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7665\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7671\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7616\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7650\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7668\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7674\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7665\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7647\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7650\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7677\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7677\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7668\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7686\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7751\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7686\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7665\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7656\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7677\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7662\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7736\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7668\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7714\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7680\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7702\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7693\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7717\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7726\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7696\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7726: 0s - loss: 0.4889 - accu\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7729\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7693\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7689\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7726\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7739\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7711\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7757\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7748\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7757\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7739\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7754\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7714\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7717\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7748\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7742\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7939\n",
      "[0.4541719853878021, 0.7938650250434875]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       409\n",
      "           1       0.80      0.78      0.79       406\n",
      "\n",
      "    accuracy                           0.79       815\n",
      "   macro avg       0.79      0.79      0.79       815\n",
      "weighted avg       0.79      0.79      0.79       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_under = ANN(X_train, X_test, y_train, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61dfb8d",
   "metadata": {},
   "source": [
    "### Method 2: Oversampling (Duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "895d7a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4a7c6056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0, count_class1 = df['Exited'].value_counts()\n",
    "count_class0, count_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "13c57dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df[df['Exited']==0]\n",
    "df_class1 = df[df['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e228e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 11)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over_class1 = df_class1.sample(count_class0, replace=True)\n",
    "df_over_class1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8a03a753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 11)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over = pd.concat([df_class0, df_over_class1], axis=0)\n",
    "df_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "65cc91c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over = df_over.drop('Exited', axis=1)\n",
    "y_over = df_over['Exited']\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ecf46daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12740, 10), (3186, 10))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=37)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4d973468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6751 - accuracy: 0.5728\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6074 - accuracy: 0.6657\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5790 - accuracy: 0.6909\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7089\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5531 - accuracy: 0.7177\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7268\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7384\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7480\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7518\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.7588\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7617\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.7723\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7716\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.7720\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7750\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7765\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7783\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7775\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.7770\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4592 - accuracy: 0.7789\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7807\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.7819\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.7807\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.7822\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4569 - accuracy: 0.7836\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7815\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.7834\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7826\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7842\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.7823\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.7848\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.7836\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.7849\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7844\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.7859\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7856\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.7862\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.7838\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.7857\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7868\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4516 - accuracy: 0.7845\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.7852\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7827\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.7854\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7853\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4492 - accuracy: 0.7885\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.7893\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7859\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.7833\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.7844\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7863\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.7863\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.7856\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.7889\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.7879\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7893\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4482 - accuracy: 0.7871\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.7865\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4492 - accuracy: 0.7863\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.7857\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7856\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7878\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.7892\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.7884\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.7863\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.7855\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7874\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.7874\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7879\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.7858\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.7880\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7864\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.7851\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.7863\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.7852\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.7880\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7871\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.78 - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7889\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7887\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.7889\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4459 - accuracy: 0.7873\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.7854\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4470 - accuracy: 0.7861\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.7877\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.7858\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.7881\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7900\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.7878\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4442 - accuracy: 0.7874\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.7897\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.7837\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.7859\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.7888\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.7887\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7894\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7734\n",
      "[0.4645019471645355, 0.7733835577964783]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78      1636\n",
      "           1       0.76      0.79      0.77      1550\n",
      "\n",
      "    accuracy                           0.77      3186\n",
      "   macro avg       0.77      0.77      0.77      3186\n",
      "weighted avg       0.77      0.77      0.77      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_over = ANN(X_train, X_test, y_train, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08aae5",
   "metadata": {},
   "source": [
    "### Method 3: Oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "217365fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9f6eba03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0, count_class1 = df['Exited'].value_counts()\n",
    "count_class0, count_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fadc07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df[df['Exited']==0]\n",
    "df_class1 = df[df['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0fa14797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d87d3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "08ad86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority', random_state=17)\n",
    "\n",
    "X_sm, y_sm = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "553381bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12740, 10), (3186, 10))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=37)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "222d3360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6828 - accuracy: 0.5694\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6326 - accuracy: 0.6623: 0s - loss: 0.6523 - \n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6914\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7100\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7238\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7353\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7466\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7506\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.7575\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.7604\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4910 - accuracy: 0.7635\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7661\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7685\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.7681\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4743 - accuracy: 0.7699\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.7705\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.7737\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7731\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.7724\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.7749\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7754\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7757\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7729\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.7787\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.7763\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7790\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7787\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4586 - accuracy: 0.7762\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.7772\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.7772\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.7772\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.7790\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.7772\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7807: 0s - loss: 0.4\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.7801\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.7785\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.7791\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.7783\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.7808\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.7822\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.7794\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.7814\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.7823\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.7767\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.7812\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7804\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.7808\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.7829\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4495 - accuracy: 0.7820\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4498 - accuracy: 0.7794\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.7833\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.7824\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7830\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7818\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.7842\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.7851\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.7842\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.7860\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7875\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4460 - accuracy: 0.7844\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.7826\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7866\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.7849\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7853\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.7866\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7850\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7860\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.7885\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.7875\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4434 - accuracy: 0.7868\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.7873\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.7881\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.7889\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.7881\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.7867\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.7894\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4443 - accuracy: 0.7870\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.7860\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.7881\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.7902\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7903\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.7902\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4411 - accuracy: 0.7906\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.7892\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7888\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.7918\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7892\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.7900\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7922\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4407 - accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7908\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4408 - accuracy: 0.7898\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.7892\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.7899\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4393 - accuracy: 0.7924\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.7917\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7897\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7884\n",
      "[0.4425051212310791, 0.7884494662284851]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1642\n",
      "           1       0.77      0.80      0.78      1544\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_smote = ANN(X_train, X_test, y_train, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7beab",
   "metadata": {},
   "source": [
    "### Method 4: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d0a4595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0, count_class1 = df['Exited'].value_counts()\n",
    "count_class0, count_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880f0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1394ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e0dd18df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a8b7ae47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6363\n",
       "1    1637\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cf4bda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2f661941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class0 = df2[df2['Exited']==0]\n",
    "df2_class1 = df2[df2['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "573a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "    \n",
    "    X_train = df_train.drop('Exited', axis=1)\n",
    "    y_train = df_train['Exited']\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "05569624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.6974 - accuracy: 0.5021\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.5519\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.5919\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.6151\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.6530 - accuracy: 0.6478\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6573\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6726\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6863\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.7001\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7126\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7230\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7355\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7437\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7401\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.7471: 0s - loss: 0.5146 - accuracy\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7465\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7492\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7532\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7550\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7566\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7532\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7547\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7587\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7599\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7621\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7624\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7608\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.7654\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7621\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7670\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7682\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7654\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7630\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7709\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7685\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7706\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7682\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7715\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7688\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7709\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7679\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7657\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7743\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7721\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7715\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7703\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7755\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7767\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7761\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7798\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7709\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7743\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7728\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7746\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7764\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7773\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7779\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7776\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7773\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7792\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7792\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7795\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7786\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7755\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7795\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7804\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7779\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7779\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7813\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7810\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7786\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7828\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7816\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7792\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7789\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7810\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7868\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7813\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795\n",
      "Epoch 80/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7807\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7828\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7783\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7850\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7770\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7816\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7825\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7828\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7838\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7789\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7828\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7816\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7844\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7789\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7807\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7871\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7798\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7807\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7871\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7767\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7780\n",
      "[0.4623406231403351, 0.777999997138977]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      1600\n",
      "           1       0.46      0.70      0.56       400\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.69      0.75      0.70      2000\n",
      "weighted avg       0.82      0.78      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train1, y_train1 = get_train_batch(df2_class0, df2_class1, 0, 1637)\n",
    "\n",
    "y_pred1 = ANN(X_train1, X_test, y_train1, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "15d72d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 2s 6ms/step - loss: 0.6879 - accuracy: 0.5382\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.5864\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5999\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6151\n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6271: 0s - loss: 0.6661 - ac\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6341\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6491\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6597\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6735\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6900\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6894\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6995\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7071\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7065\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7098\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7135\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7172\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7181\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7202\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7288\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.73 - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7312\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7361\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7395\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7398\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7407\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7410\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7434\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7471\n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7474\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7465\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7498\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7450\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7517\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7526\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7502\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7517\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7502\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7532\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7508\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7520\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7560\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7550\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7526\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7557\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7532\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7508\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7544\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7550\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7584\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7544\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7560\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7532\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7523\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7538\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7596\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7590\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7608\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7563\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7557\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7560\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7572\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7557\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7590\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7587\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7557\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7639\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7621\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7624\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7666\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7618\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7639\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7624\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7639\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7648\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7648\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7654\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7657\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7630\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7627\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7648\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7618\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7666\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7670\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7608\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7633\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7648\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7630\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7670\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7694\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7615\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7651\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7676\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7596: 0s - loss: 0.4768 - accuracy\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7663\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7633\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7627\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7694\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7633\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7648\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.7710\n",
      "[0.48365285992622375, 0.7710000276565552]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85      1600\n",
      "           1       0.45      0.65      0.53       400\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.68      0.72      0.69      2000\n",
      "weighted avg       0.81      0.77      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train2, y_train2 = get_train_batch(df2_class0, df2_class1, 1637, 3274)\n",
    "\n",
    "y_pred2 = ANN(X_train2, X_test, y_train2, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "202b6e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "103/103 [==============================] - 2s 5ms/step - loss: 0.6846 - accuracy: 0.5452\n",
      "Epoch 2/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6002\n",
      "Epoch 3/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.6097\n",
      "Epoch 4/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.6516 - accuracy: 0.6130: 0s - loss: 0.6547 \n",
      "Epoch 5/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.6304\n",
      "Epoch 6/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6466\n",
      "Epoch 7/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6741\n",
      "Epoch 8/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.6878\n",
      "Epoch 9/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5834 - accuracy: 0.7001\n",
      "Epoch 10/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.7071\n",
      "Epoch 11/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7156\n",
      "Epoch 12/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7187\n",
      "Epoch 13/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7193\n",
      "Epoch 14/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5487 - accuracy: 0.7269\n",
      "Epoch 15/100\n",
      "103/103 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7269\n",
      "Epoch 16/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7276\n",
      "Epoch 17/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7364\n",
      "Epoch 18/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7327\n",
      "Epoch 19/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7355\n",
      "Epoch 20/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7413\n",
      "Epoch 21/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7373\n",
      "Epoch 22/100\n",
      "103/103 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "103/103 [==============================] - 1s 6ms/step - loss: 0.5258 - accuracy: 0.7398\n",
      "Epoch 24/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7364\n",
      "Epoch 25/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7407\n",
      "Epoch 26/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7419\n",
      "Epoch 27/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7419\n",
      "Epoch 28/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7422: 0s - loss: 0.5121 - accuracy - ETA: 0s - loss: 0.5134 - accuracy: \n",
      "Epoch 29/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7431\n",
      "Epoch 30/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7526\n",
      "Epoch 31/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7502\n",
      "Epoch 32/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7465\n",
      "Epoch 33/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7495\n",
      "Epoch 34/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7498\n",
      "Epoch 35/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7560\n",
      "Epoch 36/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7502\n",
      "Epoch 37/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7547\n",
      "Epoch 38/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7557\n",
      "Epoch 39/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7520\n",
      "Epoch 40/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7553\n",
      "Epoch 41/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7529\n",
      "Epoch 42/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7581\n",
      "Epoch 43/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7560\n",
      "Epoch 44/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7535\n",
      "Epoch 45/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7532\n",
      "Epoch 46/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7526\n",
      "Epoch 47/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7572\n",
      "Epoch 48/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7566\n",
      "Epoch 49/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7563\n",
      "Epoch 50/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7569\n",
      "Epoch 51/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7615\n",
      "Epoch 52/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7605\n",
      "Epoch 53/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7639\n",
      "Epoch 54/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7532\n",
      "Epoch 55/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7560\n",
      "Epoch 56/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7608\n",
      "Epoch 57/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7547\n",
      "Epoch 58/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7642\n",
      "Epoch 59/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7657\n",
      "Epoch 60/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7636\n",
      "Epoch 61/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7584\n",
      "Epoch 62/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7657\n",
      "Epoch 63/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7648\n",
      "Epoch 64/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7593\n",
      "Epoch 65/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7642\n",
      "Epoch 66/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7593\n",
      "Epoch 67/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7611\n",
      "Epoch 68/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7630\n",
      "Epoch 69/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7593\n",
      "Epoch 70/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7596\n",
      "Epoch 71/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7624\n",
      "Epoch 72/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7657\n",
      "Epoch 73/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7679\n",
      "Epoch 74/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7642\n",
      "Epoch 75/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7724\n",
      "Epoch 76/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7657\n",
      "Epoch 77/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7624\n",
      "Epoch 78/100\n",
      "103/103 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7651\n",
      "Epoch 79/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7651\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7627\n",
      "Epoch 81/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7670\n",
      "Epoch 82/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7660\n",
      "Epoch 83/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7642\n",
      "Epoch 84/100\n",
      "103/103 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7663\n",
      "Epoch 85/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7703\n",
      "Epoch 86/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7670\n",
      "Epoch 87/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7673\n",
      "Epoch 88/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7651\n",
      "Epoch 89/100\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.76 - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7679\n",
      "Epoch 90/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7651\n",
      "Epoch 91/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7712\n",
      "Epoch 92/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7773\n",
      "Epoch 93/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7691\n",
      "Epoch 94/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7660\n",
      "Epoch 95/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7676\n",
      "Epoch 96/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7737\n",
      "Epoch 97/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7694\n",
      "Epoch 98/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7724\n",
      "Epoch 99/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7694\n",
      "Epoch 100/100\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7685\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.7620\n",
      "[0.4815000593662262, 0.7620000243186951]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84      1600\n",
      "           1       0.44      0.69      0.54       400\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.67      0.73      0.69      2000\n",
      "weighted avg       0.82      0.76      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train3, y_train3 = get_train_batch(df2_class0, df2_class1, 3274, 4911)\n",
    "\n",
    "y_pred3 = ANN(X_train3, X_test, y_train3, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b83af47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 2s 5ms/step - loss: 0.7074 - accuracy: 0.4749\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5892\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.6271\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.6332\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.6436\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.6581\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6711\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6882\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.6973\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.6075 - accuracy: 0.7002\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7151\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.5895 - accuracy: 0.7200\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7268\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7264\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7303\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7332\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7410\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7400\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7426\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7468\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.74 - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7530\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7504\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7540\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7523\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7530\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7533\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7543\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7566\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7601\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7559\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7595\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7601\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7611\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7585\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7643\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7608\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7653\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7627\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7656\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7659\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7630\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7595\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7643\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7630\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7640\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7591\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7666\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7630\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7663\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7656\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7666\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7630\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7679\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7653\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7698\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7646\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7663\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7669\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7663\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7666\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7663\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7724\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7637\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7672\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7698\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7653\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7679\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7663\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7724\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7708: 0s - loss: 0.4865 - accuracy: \n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7721\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7711\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7711\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7705\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7734\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7692\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7731\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7747\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7737\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7714\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7698\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7711\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7727\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7763\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7711\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7760\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7708\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7753\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7731\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7721\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7721\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7757\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7747\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7737\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7727\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7727\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7724: 0s - loss: 0.4921 - accuracy: 0.\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7750\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7682\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7365\n",
      "[0.5361136794090271, 0.7365000247955322]\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.82      1600\n",
      "           1       0.41      0.76      0.53       400\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.67      0.74      0.68      2000\n",
      "weighted avg       0.82      0.74      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train4, y_train4 = get_train_batch(df2_class0, df2_class1, 4911, 6363)\n",
    "\n",
    "y_pred4 = ANN(X_train4, X_test, y_train4, y_test, 'binary_crossentropy', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "799e50f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final = []\n",
    "for i in range(len(y_pred1)):\n",
    "    if(y_pred1[i]+y_pred2[i]+y_pred3[i]+y_pred4[i]>=2):\n",
    "        y_pred_final.append(1)\n",
    "    else:\n",
    "        y_pred_final.append(0)\n",
    "y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3b9b6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      1600\n",
      "           1       0.42      0.74      0.54       400\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.67      0.74      0.68      2000\n",
      "weighted avg       0.82      0.74      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
